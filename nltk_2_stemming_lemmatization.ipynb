{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71beb1a7-b456-4d88-8d72-e14ba9884b01",
   "metadata": {},
   "source": [
    "# **Stemming**: \n",
    "### Stemming, in Natural Language Processing (NLP), refers to the process of reducing a word to its word stem that affixes to suffixes and prefixes or the roots. \n",
    "# **Lemmatization**:\n",
    "### Lemmatization is a text pre-processing technique used in natural language processing (NLP) models to break a word down to its root meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7939002f-062f-45dc-bc4a-a4ad84b27c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"running\", \"runs\", \"ran\",\n",
    "    \"fairly\", \"sportingly\", \"understandable\",\n",
    "    \"playing\", \"plays\", \"played\",\n",
    "    \"watching\", \"watches\", \"watched\",\n",
    "    \"studying\", \"studies\", \"studied\",\n",
    "    \"going\", \"goes\", \"went\",\n",
    "    \"eating\", \"eats\", \"ate\",\n",
    "    \"fixing\", \"fixes\", \"fixed\",\n",
    "    \"crying\", \"cries\", \"cried\",\n",
    "    \"flying\", \"flies\", \"flew\",]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797be6d6-2f0a-42ec-82ec-9fe61d6c5eb1",
   "metadata": {},
   "source": [
    "## PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a5d0632-a31a-464c-9714-b78f9a6e04a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running--->>run\n",
      "runs--->>run\n",
      "ran--->>ran\n",
      "fairly--->>fairli\n",
      "sportingly--->>sportingli\n",
      "understandable--->>understand\n",
      "playing--->>play\n",
      "plays--->>play\n",
      "played--->>play\n",
      "watching--->>watch\n",
      "watches--->>watch\n",
      "watched--->>watch\n",
      "studying--->>studi\n",
      "studies--->>studi\n",
      "studied--->>studi\n",
      "going--->>go\n",
      "goes--->>goe\n",
      "went--->>went\n",
      "eating--->>eat\n",
      "eats--->>eat\n",
      "ate--->>ate\n",
      "fixing--->>fix\n",
      "fixes--->>fix\n",
      "fixed--->>fix\n",
      "crying--->>cri\n",
      "cries--->>cri\n",
      "cried--->>cri\n",
      "flying--->>fli\n",
      "flies--->>fli\n",
      "flew--->>flew\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pt_stemmer = PorterStemmer()\n",
    "for word in words:\n",
    "    stemmed_word = pt_stemmer.stem(word)\n",
    "    print(word + \"--->>\" + stemmed_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12d1e8-ce67-46de-adb5-a66e6533ba60",
   "metadata": {},
   "source": [
    "## SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c30e89-78f0-4099-9522-417db76cd402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running--->>run\n",
      "runs--->>run\n",
      "ran--->>ran\n",
      "fairly--->>fair\n",
      "sportingly--->>sport\n",
      "understandable--->>understand\n",
      "playing--->>play\n",
      "plays--->>play\n",
      "played--->>play\n",
      "watching--->>watch\n",
      "watches--->>watch\n",
      "watched--->>watch\n",
      "studying--->>studi\n",
      "studies--->>studi\n",
      "studied--->>studi\n",
      "going--->>go\n",
      "goes--->>goe\n",
      "went--->>went\n",
      "eating--->>eat\n",
      "eats--->>eat\n",
      "ate--->>ate\n",
      "fixing--->>fix\n",
      "fixes--->>fix\n",
      "fixed--->>fix\n",
      "crying--->>cri\n",
      "cries--->>cri\n",
      "cried--->>cri\n",
      "flying--->>fli\n",
      "flies--->>fli\n",
      "flew--->>flew\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "sb_stemmer = SnowballStemmer('english')\n",
    "for word in words:\n",
    "    stemmed_word = sb_stemmer.stem(word)\n",
    "    print(word + \"--->>\" + stemmed_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd1da5-ff61-475c-a324-46278a3c6253",
   "metadata": {},
   "source": [
    "## WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0745a3d6-bdab-4e65-a747-73b9622d7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running----->>run\n",
      "runs----->>run\n",
      "ran----->>run\n",
      "fairly----->>fairly\n",
      "sportingly----->>sportingly\n",
      "understandable----->>understandable\n",
      "playing----->>play\n",
      "plays----->>play\n",
      "played----->>play\n",
      "watching----->>watch\n",
      "watches----->>watch\n",
      "watched----->>watch\n",
      "studying----->>study\n",
      "studies----->>study\n",
      "studied----->>study\n",
      "going----->>go\n",
      "goes----->>go\n",
      "went----->>go\n",
      "eating----->>eat\n",
      "eats----->>eat\n",
      "ate----->>eat\n",
      "fixing----->>fix\n",
      "fixes----->>fix\n",
      "fixed----->>fix\n",
      "crying----->>cry\n",
      "cries----->>cry\n",
      "cried----->>cry\n",
      "flying----->>fly\n",
      "flies----->>fly\n",
      "flew----->>fly\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for word in words:\n",
    "    lemmatized_word = lemmatizer.lemmatize(word, pos= 'v')\n",
    "    print(word + \"----->>\" + lemmatized_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b981e-f6ff-41b7-bfe1-9dd7bf59b849",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405f860e-fc25-4812-af86-fd4900b50b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Word</th>\n",
       "      <th>PorterStemmed Word</th>\n",
       "      <th>SnowballStemmed Word</th>\n",
       "      <th>Lemmatized Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>running</td>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>runs</td>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ran</td>\n",
       "      <td>ran</td>\n",
       "      <td>ran</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fairly</td>\n",
       "      <td>fairli</td>\n",
       "      <td>fair</td>\n",
       "      <td>fairly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sportingly</td>\n",
       "      <td>sportingli</td>\n",
       "      <td>sport</td>\n",
       "      <td>sportingly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>understandable</td>\n",
       "      <td>understand</td>\n",
       "      <td>understand</td>\n",
       "      <td>understandable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>playing</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>plays</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>played</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "      <td>play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>watching</td>\n",
       "      <td>watch</td>\n",
       "      <td>watch</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>watches</td>\n",
       "      <td>watch</td>\n",
       "      <td>watch</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>watched</td>\n",
       "      <td>watch</td>\n",
       "      <td>watch</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>studying</td>\n",
       "      <td>studi</td>\n",
       "      <td>studi</td>\n",
       "      <td>study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>studies</td>\n",
       "      <td>studi</td>\n",
       "      <td>studi</td>\n",
       "      <td>study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>studied</td>\n",
       "      <td>studi</td>\n",
       "      <td>studi</td>\n",
       "      <td>study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>going</td>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>goes</td>\n",
       "      <td>goe</td>\n",
       "      <td>goe</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>went</td>\n",
       "      <td>went</td>\n",
       "      <td>went</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>eating</td>\n",
       "      <td>eat</td>\n",
       "      <td>eat</td>\n",
       "      <td>eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>eats</td>\n",
       "      <td>eat</td>\n",
       "      <td>eat</td>\n",
       "      <td>eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ate</td>\n",
       "      <td>ate</td>\n",
       "      <td>ate</td>\n",
       "      <td>eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fixing</td>\n",
       "      <td>fix</td>\n",
       "      <td>fix</td>\n",
       "      <td>fix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fixes</td>\n",
       "      <td>fix</td>\n",
       "      <td>fix</td>\n",
       "      <td>fix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>fixed</td>\n",
       "      <td>fix</td>\n",
       "      <td>fix</td>\n",
       "      <td>fix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>crying</td>\n",
       "      <td>cri</td>\n",
       "      <td>cri</td>\n",
       "      <td>cry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cries</td>\n",
       "      <td>cri</td>\n",
       "      <td>cri</td>\n",
       "      <td>cry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cried</td>\n",
       "      <td>cri</td>\n",
       "      <td>cri</td>\n",
       "      <td>cry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>flying</td>\n",
       "      <td>fli</td>\n",
       "      <td>fli</td>\n",
       "      <td>fly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "      <td>fli</td>\n",
       "      <td>fly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>flew</td>\n",
       "      <td>flew</td>\n",
       "      <td>flew</td>\n",
       "      <td>fly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Original Word PorterStemmed Word SnowballStemmed Word Lemmatized Word\n",
       "0          running                run                  run             run\n",
       "1             runs                run                  run             run\n",
       "2              ran                ran                  ran             run\n",
       "3           fairly             fairli                 fair          fairly\n",
       "4       sportingly         sportingli                sport      sportingly\n",
       "5   understandable         understand           understand  understandable\n",
       "6          playing               play                 play            play\n",
       "7            plays               play                 play            play\n",
       "8           played               play                 play            play\n",
       "9         watching              watch                watch           watch\n",
       "10         watches              watch                watch           watch\n",
       "11         watched              watch                watch           watch\n",
       "12        studying              studi                studi           study\n",
       "13         studies              studi                studi           study\n",
       "14         studied              studi                studi           study\n",
       "15           going                 go                   go              go\n",
       "16            goes                goe                  goe              go\n",
       "17            went               went                 went              go\n",
       "18          eating                eat                  eat             eat\n",
       "19            eats                eat                  eat             eat\n",
       "20             ate                ate                  ate             eat\n",
       "21          fixing                fix                  fix             fix\n",
       "22           fixes                fix                  fix             fix\n",
       "23           fixed                fix                  fix             fix\n",
       "24          crying                cri                  cri             cry\n",
       "25           cries                cri                  cri             cry\n",
       "26           cried                cri                  cri             cry\n",
       "27          flying                fli                  fli             fly\n",
       "28           flies                fli                  fli             fly\n",
       "29            flew               flew                 flew             fly"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pt_stemmed_words = []\n",
    "sb_stemmed_words = []\n",
    "lemmatized_words = []\n",
    "for word in words:\n",
    "    pt_stemmed_word = pt_stemmer.stem(word)\n",
    "    sb_stemmed_word = sb_stemmer.stem(word)\n",
    "    lemmatized_word = lemmatizer.lemmatize(word, pos = 'v')\n",
    "    pt_stemmed_words.append(pt_stemmed_word)\n",
    "    sb_stemmed_words.append(sb_stemmed_word)\n",
    "    lemmatized_words.append(lemmatized_word)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Original Word': words,\n",
    "    'PorterStemmed Word': pt_stemmed_words,\n",
    "    'SnowballStemmed Word': sb_stemmed_words,\n",
    "    'Lemmatized Word': lemmatized_words})\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc28ed-2a03-48df-a728-ae5211fd003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemmatizing >> SnowballStemmer >> PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01971107-bb3c-47fc-98a0-f581eaaef873",
   "metadata": {},
   "source": [
    "# Usecases\n",
    "1. Stemming >> Classification like Sentiment Classification\n",
    "2. Lemmatizing >> Chatbots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf227e9-7fa0-4ffb-ad22-93d613579695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
